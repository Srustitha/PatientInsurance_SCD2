{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81e50d48-cfea-41d2-b489-72290b353178",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pyspark.sql import Row\n",
    "import os\n",
    "\n",
    "def log_event_file(\n",
    "    pipeline_name,\n",
    "    notebook_name,\n",
    "    layer_name,\n",
    "    status,\n",
    "    message=\"\",\n",
    "    record_count=0,\n",
    "    event_time=None\n",
    "):\n",
    "\n",
    "    # ---------- Set event time ----------\n",
    "    if event_time is None:\n",
    "        event_time = datetime.now()\n",
    "\n",
    "    timestamp = event_time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    # ---------- Local log path (DBFS local storage) ----------\n",
    "    # This stores logs in Databricks File System (acts like local system)\n",
    "    local_log_dir = \"/Volumes/workspace/default/patientinsurance_logfiles/\"\n",
    "\n",
    "    os.makedirs(local_log_dir, exist_ok=True)\n",
    "\n",
    "    file_name = f\"{pipeline_name}_{layer_name}_{timestamp}.log\"\n",
    "    full_local_path = f\"{local_log_dir}{file_name}\"\n",
    "\n",
    "    # ---------- Log content ----------\n",
    "    log_text = f\"\"\"\n",
    "Event Time   : {event_time}\n",
    "Pipeline     : {pipeline_name}\n",
    "Notebook     : {notebook_name}\n",
    "Layer        : {layer_name}\n",
    "Status       : {status}\n",
    "Record Count : {record_count}\n",
    "Message      : {message}\n",
    "\"\"\"\n",
    "\n",
    "    # ---------- Write .log file locally ----------\n",
    "    with open(full_local_path, \"w\") as f:\n",
    "        f.write(log_text)\n",
    "\n",
    "    # ---------- Write audit record to Delta table ----------\n",
    "    audit_row = Row(\n",
    "        event_time=event_time,\n",
    "        pipeline_name=pipeline_name,\n",
    "        notebook_name=notebook_name,\n",
    "        layer_name=layer_name,\n",
    "        status=status,\n",
    "        record_count=record_count,\n",
    "        message=message,\n",
    "        log_file_path=full_local_path\n",
    "    )\n",
    "\n",
    "    spark.createDataFrame([audit_row]) \\\n",
    "        .write.mode(\"append\") \\\n",
    "        .saveAsTable(\"audit_logs\")\n",
    "\n",
    "    print(f\"Log created â†’ {full_local_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d00f6e9-1483-4859-9f11-de591e909e65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# drop table audit_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c8f9ca5-11e5-4af8-b8bb-3b24d43fcc5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# select * from audit_logs order by event_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f80ef7bb-6b60-4659-8f86-97f250b45fe9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5529956329437690,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Log_Files",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
